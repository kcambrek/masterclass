{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masterclass Unsupervised analysis \n",
    "## Hands on session 4 - Dimensionality reduction and embeddings\n",
    "#### Rijkswaterstaat | Datalab | E. Taskesen | Oct 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA and other embeddings are extremely usefull for visualizing a high-dimensional dataset in 2D for understanding its intrinsic structure. In this notebook we will use existing data sets, and experiment with various dimensionality reduction techniques and embeddings, such as Principal Component Analysis (PCA), t-SNE. In addition we will analyze the \"goodness\" of high-dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../src/\"))\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from clusteval import clusteval\n",
    "from scatter import scatter\n",
    "from biplot import biplot\n",
    "from tsneBH import tsneBH\n",
    "from flameplot import flameplot\n",
    "from stringMatchALIAS import stringMatchALIAS\n",
    "from scatter import scatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Principal Component Analysis</h2>\n",
    "<h3>The algorithm</h3>\n",
    "\n",
    "Principal component analysis (PCA) involves a mathematical procedure that transforms a number of (possibly) correlated variables into a (smaller) number of uncorrelated variables called principal components. The first principal component accounts for as much of the variability in the data as possible, and each succeeding component accounts for as much of the remaining variability as possible.\n",
    "\n",
    "<br><b>Objectives of principal component analysis</b>\n",
    "<br>•\t1. To reduce the dimensionality\n",
    "<br>•\t2. To discover/explore the data set.\n",
    "<br>•\t3. To identify new meaningful underlying variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can start with either, filtered data or if you are not sure, the full dataset.\n",
    "Reduce the dimensionality to 2 dimensions and plot the first two principle components and why are the first principle components more important than the last ones?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "Lets try again but now on real data\n",
    "Load a real cancer data from The Cancer Genome Atlas (TCGA). This dataset contains tens of thousands of features (genes), and over 4000 human cancer samples.\n",
    "Your goal is to determine the relationships of different human-samples and their cancer-types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer dataset\n",
    "df         = pd.read_csv('../data/TCGA_RAW.zip',compression='zip')\n",
    "metadata   = pd.read_csv('../data/metadata.csv', sep=';')\n",
    "features   = pd.read_csv('../data/features.csv')\n",
    "df.columns = metadata.labx.values\n",
    "df.index   = features.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RAW data to normalized data\n",
    "data = df.copy()\n",
    "dataL = np.log2(data+1)\n",
    "dataLZ = dataL.copy()\n",
    "rowmeans=np.mean(dataL, axis=1)\n",
    "for i in range(dataLZ.shape[0]):\n",
    "    dataLZ.iloc[i,:] = dataL.values[i,:] - rowmeans[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top discriminating features\n",
    "minvar=8\n",
    "featvar=dataLZ.var(axis=1)\n",
    "dataLZF = dataLZ.iloc[np.where(featvar>=minvar)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Bi-plot\n",
    "pcaout=biplot(dataLZF.values.T, labx=metadata.labx.values, features=dataLZF.index.values, components=0.95, showfig=1,  width=8, height=6, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would be an appriorate number of PCs to reduce the dimensionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much variance is covered by the first two components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaout['expl_var_perc'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the first 1th and 2nd principle components. Why do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=scatter(pcaout['PC'][:,0],pcaout['PC'][:,1], labx=metadata.labx.values, density_type='all', labx_type='unique', width=6, height=6, xlabel='PC20', ylabel='PC21', title='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the first 20th and 21th principle components. Why do you not see any differences between the different cancer classes in this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=scatter(pcaout['PC'][:,19],pcaout['PC'][:,20], labx=metadata.labx.values, labx_type='unique', width=6, height=6, xlabel='PC20', ylabel='PC21', title='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To idenfity new meaningfull features, we can examine the loadings. Plot the loadings. What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaout=biplot(dataLZF.values.T, labx=metadata.labx.values, features=dataLZF.index.values, components=0.95, showfig=2,  width=18, height=16, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loadings of for the first principal component. What can you conclude from that?\n",
    "PC=1\n",
    "\n",
    "PC = PC-1\n",
    "pcaout['loadings'][PC,:]\n",
    "#plt.plot(pcaout['loadings'][PC,:])\n",
    "\n",
    "#pcaout['topFeat']\n",
    "I1=np.argsort(np.abs(pcaout['loadings'][PC,:]))\n",
    "I1=I1[::-1]\n",
    "\n",
    "# Take the top 10\n",
    "I1=I1[0:np.min([10,len(I1)])]\n",
    "dataLZF.index[I1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>tSNE</h2>\n",
    "<h3>The algorithm</h3>\n",
    "\n",
    "<br><b>Objectives of tSNE</b>\n",
    "<br>•\t1. To reduce the dimensionality\n",
    "<br>•\t2. To discover/explore the data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout=tsneBH(dataLZF.values.T, showprogress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter\n",
    "scatter(tout[:,0],tout[:,1], labx=metadata.labx.values, labx_type='unique', size=2, width=15, height=10, title='REAL labels', plottype='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine clusters\n",
    "clustlabx=clusteval(tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter\n",
    "scatter(tout[:,0],tout[:,1], labx=clustlabx['labx'], size=2, labx_type='unique', width=15, height=10, title='Estimated clusters', plottype='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cluster labels with class-labels\n",
    "scatter(tout[:,0],tout[:,1], labx=metadata.labx.values, density_labx=clustlabx['labx'], density_levels=7, density=2, size=15, labx_type='unique', width=15, height=15, title='Estimated clusters', plottype='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The best possible tSNE can be derived by running it e.g., 1000x and then taking the one with lowest divergence (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE CASE: Find similar strings in a data driven manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data              = pd.read_csv(\"../data/marketing_data_online_retail_small.csv\",sep=';')\n",
    "data              = data.Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS have a look at your data!\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best matches for the following four alias's\n",
    "alias             = ['lantern','cream cupid hearts coat hanger','tlight holder','light']\n",
    "[outDIST,outBIN] = stringMatchALIAS(data[0:50],data[0:50], scoreOK=[1,0.7,0.8,1])\n",
    "\n",
    "# This outputs a sparse datamatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all possible matches by fuzzy string matching\n",
    "[outDIST,outBIN] = stringMatchALIAS(data[0:500],data[0:500], methodtype='FUZZY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize your data!\n",
    "outxy = tsneBH(outDIST.values, metric='precomputed')\n",
    "labx  = clusteval(outxy)\n",
    "#labx  = HDBSCAN(outxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(outxy[:,0],outxy[:,1], labx=labx['labx'], labx_txt=outDIST.columns.str.lower().str.strip().values, labx_type='', size=5, plottype='bokeh')\n",
    "scatter(outxy[:,0],outxy[:,1], labx=labx['labx'], labx_txt=outDIST.columns.str.lower().str.strip().values, labx_type='all', size=5, plottype='bokeh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>High vs Low dimensionality</h2>\n",
    "<br><b>When performing a dimensionality reduction, we want to preserve as good as possible the high-dimensional structure</b>\n",
    "\n",
    "<h3>The algorithm</h3>\n",
    "Quantification of Local similarity across two maps\n",
    "To compare the embedding of samples in two different maps, we propose a scale dependent similarity measure. For a pair of maps X and Y, we compare the sets of the, respectively, kx and ky nearest neighbours of each sample. We first define the variable rxij as the rank of the distance of sample j among all samples with respect to sample i, in map X. The nearest neighbor of sample i will have rank 1, the second nearest neighbor rank 2, etc. Analogously, ryij is the rank of sample j with respect to sample i in map Y. Now we define a score on the interval [0, 1], as (eq. 1)\n",
    "\n",
    "Where the variable n is the total number of samples, and the indicator function is given by (eq. 2)\n",
    "\n",
    "The score sx,y(kx, ky) will have value 1 if, for each sample, all kx nearest neighbours in map X are also the ky nearest neighbours in map Y, or vice versa. For the analysis in Fig. 3 we have used kx = ky = 20. Other settings of kx and ky can be found in the supplement (Fig. S18). Note that a local neighborhood of 20 samples (that we used in our experimental settings) is based on the cancer-tissue with the smallest number of samples (i.e., PAAD). For the analysis in Supplementary Fig. S3, panel b–e we used kxy = 250 which is the average of the cancer-tissue group size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouflame=flameplot(tout,pcaout['PC'], nn=150, steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
